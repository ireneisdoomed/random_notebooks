{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/irene/miniconda3/envs/pyspark/lib/python3.7/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/10 12:54:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .master('local[*]')\n",
    "         .config(\"spark.driver.memory\", \"15g\")\n",
    "         .appName('spark')\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "List of HGVS identifier -> list of target genes provided by VEP\n",
    "- 6731 variants. 608 with more than 5 genes. 1190 with more than 3 genes.\n",
    "  - If we go for the cutoff of 3 I guess extracting their impact is no longer of interest.\n",
    "- 3770 variants with uncertain coordinates. Most of the cases (3510) with unknown bounds.\n",
    "  - We want to keep them but taking a conservative approach.\n",
    "  - Problem in indexing these. We will have multiple ids that actually refer to the same phenomenom.\n",
    "- 177 variants are mapped to a target different than Ensembl (LRG).\n",
    "\n",
    "### Questions\n",
    "1. Do we want to establish a threshold for a maximum nmber of targets to be used? Yes. Most likely a cutoff of 3. We will be dropping the more promiscuous cases.\n",
    "2. How many of all the complex variants were accessible by VEP?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/vep-annotated-complex.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = pd.DataFrame({\n",
    "    \"variantId\": list(data.keys()),\n",
    "    \"targetIds\": list(data.values())\n",
    "  })\n",
    "# var.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|           variantId|           targetIds|\n",
      "+--------------------+--------------------+\n",
      "|NC_000001.11:g.20...|   [ENSG00000075151]|\n",
      "|NC_000006.12:g.10...|[ENSG00000230314,...|\n",
      "|NC_000002.12:g.23...|[ENSG00000163295,...|\n",
      "|NC_000019.10:g.14...|[ENSG00000115257,...|\n",
      "|NC_000006.12:g.52...|   [ENSG00000244067]|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var_df = spark.createDataFrame(var)\n",
    "var_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df = var_df.withColumn('s', F.size(F.col('targetIds')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---+\n",
      "|           variantId|           targetIds|  s|\n",
      "+--------------------+--------------------+---+\n",
      "|NC_000013.11:g.46...|[ENSG00000232954,...|437|\n",
      "|NC_000015.10:g.22...|[ENSG00000259905,...|251|\n",
      "|NC_000005.10:g.(5...|[ENSG00000249238,...|232|\n",
      "|NC_000017.11:g.(?...|[ENSG00000205266,...|230|\n",
      "|NC_000021.9:g.(10...|[ENSG00000232193,...|220|\n",
      "+--------------------+--------------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var_df.orderBy(F.col('s').desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+----------------------------------+---+\n",
      "|variantId                                         |targetIds                         |s  |\n",
      "+--------------------------------------------------+----------------------------------+---+\n",
      "|NC_000001.11:g.20810811_20829210del               |[ENSG00000075151]                 |1  |\n",
      "|NC_000006.12:g.52751643_52757905del               |[ENSG00000244067]                 |1  |\n",
      "|NC_000023.11:g.124061012_124094911del             |[ENSG00000101972]                 |1  |\n",
      "|NC_000022.11:g.(?_41092585)_(41093099_41117186)del|[ENSG00000100393, ENSG00000284015]|2  |\n",
      "|NC_000019.10:g.(?_7112255)_(7249328_?)del         |[ENSG00000171105]                 |1  |\n",
      "+--------------------------------------------------+----------------------------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var_df_cutoff = var_df.filter(F.col('s') < 3)\n",
    "var_df_cutoff.show(5, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3510"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_df_cutoff.filter(F.col('variantId').contains('?')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|           variantId| targetIds|\n",
      "+--------------------+----------+\n",
      "|LRG_292:g.96347_1...| [LRG_292]|\n",
      "|LRG_1121:g.69063_...|[LRG_1121]|\n",
      "|LRG_487:g.(19968_...| [LRG_487]|\n",
      "|LRG_292:g.142345_...| [LRG_292]|\n",
      "|LRG_292:g.139830_...| [LRG_292]|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var_df.withColumn('targetId', F.explode(F.col('targetIds'))).filter(~F.col('targetId').contains('ENS')).select('variantId', 'targetIds').distinct().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4b6dc36c032161cfa2dcc93f31fcb0bfb11bc6fea6f0772b15a0710e4778680"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
